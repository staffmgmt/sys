# filename: newp/browser_use/agent/prompts.py
import importlib.resources # For loading system_prompt.md if it were still a separate file
import logging # Added for PlannerPrompt
import json
from datetime import datetime
from typing import TYPE_CHECKING, Any, Dict, List, Optional, Union # Added Any, Dict

from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage # Added BaseMessage

# Conditional imports for type checking to avoid circular dependencies
if TYPE_CHECKING:
    from browser_use.agent.views import ActionResult, AgentStepInfo
    from browser_use.browser.views import BrowserState
    # BrowserState might be from browser.views, AgentState from agent.views. Clarify based on usage.
    # Assuming BrowserState here refers to the snapshot used for prompting.

logger = logging.getLogger(__name__) # Standard logger for PlannerPrompt

# --- Main Agent System Prompt Content (aligned with finalized system_prompt.md) ---
# For maintainability, this could be loaded from system_prompt.md at runtime,
# but embedding it ensures it's packaged. The original loaded it. Let's keep that pattern.

def load_system_prompt_markdown() -> str:

    try:
        # This assumes 'system_prompt.md' is a sibling to 'prompts.py' within the 'agent' package.
        # Adjust path if 'system_prompt.md' is located elsewhere relative to 'browser_use.agent'.
        # The original used importlib.resources.files('browser_use.agent').joinpath('system_prompt.md')
        # which is robust for installed packages.
        with importlib.resources.files('browser_use.agent').joinpath('system_prompt.md').open('r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        # Fallback or raise a more critical error if the prompt is essential
        logger.error(f"Failed to load system_prompt.md: {e}. Using a basic fallback system prompt.")
        # Basic fallback if file loading fails, to prevent full crash.
        return "You are a helpful AI assistant. Follow instructions carefully."


class SystemPrompt:

    def __init__(
        self,
        # action_description is now part of the markdown file, no longer passed here.
        max_actions_per_step: int = 7, # Default from updated AgentSettings
        override_system_message: Optional[str] = None,
        extend_system_message: Optional[str] = None,
    ):
        self.max_actions_per_step = max_actions_per_step
        
        prompt_content: str
        if override_system_message:
            prompt_content = override_system_message
        else:
            base_template = load_system_prompt_markdown()
            # Replace placeholders in the loaded markdown template
            # Current main placeholder is {max_actions_per_step}
            prompt_content = base_template.format(max_actions_per_step=self.max_actions_per_step)

        if extend_system_message:
            prompt_content += f'\n\n{extend_system_message}'

        self.system_message_obj = SystemMessage(content=prompt_content)

    def get_system_message(self) -> SystemMessage:

        return self.system_message_obj


class AgentMessagePrompt:

    def __init__(
        self,
        current_browser_state: 'BrowserState', # Changed from state: 'BrowserState' to be more specific
        # result: Optional[List['ActionResult']] = None, # Removed: Results are part of history now
        include_attributes: Optional[List[str]] = None, # Retained from original
        step_info: Optional['AgentStepInfo'] = None, # Retained from original
    ):
        self.current_browser_state = current_browser_state
        self.include_attributes = include_attributes if include_attributes is not None else [
            'title', 'type', 'name', 'role', 'tabindex', 'aria-label', 'placeholder', 'value', 'alt', 'aria-expanded', # Default attributes
        ]
        self.step_info = step_info

    def get_user_message(self, use_vision: bool = True) -> HumanMessage:
        elements_text = "Error: DOM element tree not available or could not be processed for prompt." # Default/fallback
        if self.current_browser_state and self.current_browser_state.element_tree:
            if hasattr(self.current_browser_state.element_tree, 'clickable_elements_to_string'):
                try:
                    generated_elements_text = self.current_browser_state.element_tree.clickable_elements_to_string(
                        include_attributes=self.include_attributes
                    )
                    if generated_elements_text and generated_elements_text.strip():
                        elements_text = generated_elements_text
                    else:
                        elements_text = "No interactive elements identified by clickable_elements_to_string."
                except Exception as e_to_str: 
                    logger.error(f"Error calling clickable_elements_to_string: {e_to_str}", exc_info=True) 
                    elements_text = "Error formatting interactive elements string for prompt." 
            else:
                elements_text = "DOM element tree is present but missing expected formatting method."
        elif not self.current_browser_state:
            elements_text = "Error: Browser state not available for prompt generation."

        if elements_text and elements_text != "No interactive elements identified or page is empty." and not elements_text.startswith("Error:") and not elements_text.startswith("DOM element tree not available"):
            pixels_above = getattr(self.current_browser_state, 'pixels_above', 0) if self.current_browser_state else 0
            pixels_below = getattr(self.current_browser_state, 'pixels_below', 0) if self.current_browser_state else 0
            has_content_above = pixels_above > 0
            has_content_below = pixels_below > 0

            if has_content_above:
                elements_text = f"... Content above ({pixels_above}px) - Scroll up or use extract_content ...\n{elements_text}"
            elif elements_text != "No interactive elements identified by clickable_elements_to_string.":
                elements_text = f"[Top of Scrollable Content]\n{elements_text}"

            if has_content_below:
                elements_text = f"{elements_text}\n... Content below ({pixels_below}px) - Scroll down or use extract_content ..."
            elif elements_text != "No interactive elements identified by clickable_elements_to_string.":
                elements_text = f"{elements_text}\n[Bottom of Scrollable Content]"
        elif not elements_text.strip(): 
            elements_text = "No interactive elements identified or page is empty."

        step_info_description_parts = []
        if self.step_info:
            step_info_description_parts.append(f"Current step execution: {self.step_info.step_number + 1}/{self.step_info.max_steps}")
        
        time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S %Z')
        step_info_description_parts.append(f"Current Timestamp: {time_str}")
        step_info_str = " | ".join(filter(None, step_info_description_parts))

        url_str = self.current_browser_state.url if self.current_browser_state else "Unknown URL"
        title_str = self.current_browser_state.title if self.current_browser_state else "N/A"
        
        tabs_list = []
        if self.current_browser_state and self.current_browser_state.tabs:
            try:
                tabs_list = [tab.model_dump() for tab in self.current_browser_state.tabs]
            except Exception as e_tabs:
                logger.error(f"Error serializing tabs for prompt: {e_tabs}")
                tabs_list = [{"error": "Could not serialize tab info"}]
        tabs_str = json.dumps(tabs_list) if tabs_list else "No tab info available."


        observation_description = (
            f"--- CURRENT OBSERVATION ---\n"
            f"URL: {url_str}\n"
            f"Page Title: {title_str}\n"
            f"Open Tabs Overview: {tabs_str}\n"
            f"Interactive Elements on Current Page (Viewport Focus):\n{elements_text}\n"
            f"{step_info_str}\n"
            f"--- END CURRENT OBSERVATION ---"
        )
        
        content_for_llm: List[Dict[str, Any]] = [{"type": "text", "text": observation_description}]

        if self.current_browser_state and self.current_browser_state.screenshot and use_vision:
            logger.debug("Adding screenshot to current observation prompt.")
            content_for_llm.append({
                "type": "image_url",
                "image_url": {"url": f"data:image/png;base64,{self.current_browser_state.screenshot}"},
            })
        
        return HumanMessage(content=content_for_llm)

# --- Planner/Reflector Prompt (incorporating user's refined version) ---
DEFAULT_PLANNER_PROMPT_TEMPLATE = """Directive: Analyze AI agent web/file tasks. Output JSON: memory_summary, next_goal, effective_strategy?.
Context Inputs:task (overall objective), previous_plan (last aim), recent_history (agent log: steps, plans, outcomes, errors, outputs, Agent_Dir interactions), current_url, vision screenshot (if enabled), error_context_for_planner.
Agent Operating Model:

Element Interaction: [idx]<type>text</type>; only []-indexed elements actionable via unique idx. Context: hierarchy (\t), new elements (* on stable URL), visual labels mapped to idx.
Core Actions: Goals use atomic actions (e.g., click_element, input_text, go_to_url, extract_content, wait, done). next_goal must be resolvable thus.
State & Memory: Agent maintains detailed step-by-step memory (e.g., iteration counts, sub-results) and self-evaluates goal success. Planner's memory_summary is strategic overlay.
Error Handling: Agent attempts basic recovery (back, retry, new search); understands form interruptions signal dynamic content.
Task Completion: done action signals task end (overall or max_steps) with success flag. Agent tracks iterative aspects internally.
Generation Mandate:

Review Context: Analyze inputs via Agent Operating Model, spotlighting errors, history patterns, Agent_Dir activity.
memory_summary: Synthesize critical learnings, Agent_Dir changes, obstacles, task status. Concise, comprehensive; informs strategy.
next_goal: Define immediate, actionable, high-level strategic goal. Specific, achievable, error-responsive, respecting agent limits (e.g., "Extract data pattern X from current page via extract_content.", "Retry form on error '{{Y}}' after refresh.").
effective_strategy (Optional): Identify reusable approach, core learning, or effective pattern (e.g., "For multi-step entry, advise agent Agent_Dir saves post-step.", "If navigation fails, direct agent to search fallback."). Null/omit if none.
Output: Single, valid JSON. No external prose.

**Overall Task Description:**
{task}

**Previous High-Level Goal/Plan:**
{previous_plan}

**Recent Execution History (Newest entries first, focus on outcomes and Agent_Dir interactions):**
{recent_history}

**Current Error Context (If any, from previous step):**
{error_context_for_planner}

**Current Browser State:**
- URL: {current_url}
- (A screenshot of the current page is provided as image input if vision is enabled for the planner)

**REQUIRED JSON OUTPUT SCHEMA:**
```json
{{
  "memory_summary": "string: Concise, cumulative summary of progress, key findings (web and Agent_Dir), current status, and relevant context learned since the last reflection. This is the agent's current task working memory.",
  "next_goal": "string: Clear, actionable, and immediate high-level strategic goal for the agent's next phase of operations. Be specific.",
  "effective_strategy": "string | null: (Optional) Description of a reusable strategy, learning, or effective pattern identified. Null or omit if not applicable."
}}
Now, perform your reflection and planning based on all the provided information and strictly output the JSON object."""

class PlannerPrompt: 

    def __init__(self, template: Optional[str] = None): 
        self.template = template or DEFAULT_PLANNER_PROMPT_TEMPLATE 
        # self._load_template_if_needed()

    def _load_template_if_needed(self): 
        pass 


    def format_text_content(self, **kwargs: Any) -> str: 
        expected_keys = ["task", "previous_plan", "recent_history", "current_url", "error_context_for_planner"] # Added "error_context_for_planner"
        for key in expected_keys: 
            kwargs.setdefault(key, f"<{key} was not provided in context>") 
        
        if 'recent_history' in kwargs and len(kwargs['recent_history']) > 15000: 
             kwargs['recent_history'] = kwargs['recent_history'][:15000] + "\n... (recent history truncated for planner prompt display) ..." 
        
        return self.template.format(**kwargs) 

    def get_prompt_messages( 
        self,
        use_vision: bool,
        screenshot_base64: Optional[str], 
        **kwargs_for_text_format: Any 
    ) -> List[BaseMessage]:

        formatted_text_part = self.format_text_content(**kwargs_for_text_format) 

        message_content_list: List[Union[str, Dict[str, Any]]] = [ 
            {"type": "text", "text": formatted_text_part} 
        ] 

        if use_vision and screenshot_base64: 
            logger.debug("Adding screenshot to Reflector/Planner prompt.") 
            message_content_list.append({ 
                "type": "image_url",
                "image_url": {"url": f"data:image/png;base64,{screenshot_base64}"},
            })
        else: 
            logger.debug("Screenshot not provided or vision disabled for Reflector/Planner prompt.") 
            if use_vision and not screenshot_base64: 
                 logger.warning("Planner vision enabled, but no screenshot data was provided for the current step.") 

        return [HumanMessage(content=message_content_list)]